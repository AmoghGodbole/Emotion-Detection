# Emotion-Detection
This project aims at providing help to people struggling with mental health issues (mainly elderly citizens with a few to no people to express their emotions to). 
The user can upload a handwritten note, or record an audio 
and express their feelings about a certain pre-decided topic (for eg. their favorite childhood memory). The website then performs emotion detection and analysis
on the input and assigns a score 
to the user, which incorporates the strength of the language used and the length of the input. Using this, the users can then realize their feelings about the 
issue at hand and adopt appropriate steps to mitigate their moods, in case they're negative at that point.

The home page looks as follows:

<img width="960" alt="image" src="https://user-images.githubusercontent.com/69348639/218020378-9e1fc501-77db-4237-b505-0016f029ee76.png">

<img width="960" alt="image" src="https://user-images.githubusercontent.com/69348639/218020431-4f533151-d1b5-4b6b-93b9-0c98a17e61d7.png">

There are several prompts given in the "Get Started" section, with writing or speaking options for both:

<img width="960" alt="image" src="https://user-images.githubusercontent.com/69348639/218020732-077ce144-4479-4802-9b52-448dee1e9981.png">

<img width="960" alt="image" src="https://user-images.githubusercontent.com/69348639/218020807-c25448cb-1210-49dc-ad8b-be02eefcb9bb.png">

<img width="960" alt="image" src="https://user-images.githubusercontent.com/69348639/218020861-742efceb-2987-4ca4-927e-e390a13d433b.png">

Suppose a user decides to upload a handwritten note about the first topic:

<img width="960" alt="image" src="https://user-images.githubusercontent.com/69348639/218021310-6e1593d3-52b2-4714-aef7-f270d86804b5.png">

The system uses OCR to convert this into computer-recognizable text and then performs emotion detection and analysis on that text.
